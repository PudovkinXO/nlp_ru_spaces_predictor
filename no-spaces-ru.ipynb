{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13221090,"sourceType":"datasetVersion","datasetId":8324957},{"sourceId":13221498,"sourceType":"datasetVersion","datasetId":8373267}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\ndata = pd.read_csv('/kaggle/input/train-data/train_data.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T21:43:26.676594Z","iopub.execute_input":"2025-09-30T21:43:26.677201Z","iopub.status.idle":"2025-09-30T21:43:28.054057Z","shell.execute_reply.started":"2025-09-30T21:43:26.677175Z","shell.execute_reply":"2025-09-30T21:43:28.053517Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T21:43:32.570032Z","iopub.execute_input":"2025-09-30T21:43:32.570740Z","iopub.status.idle":"2025-09-30T21:43:32.626492Z","shell.execute_reply.started":"2025-09-30T21:43:32.570714Z","shell.execute_reply":"2025-09-30T21:43:32.625694Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.tail()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T21:43:49.120200Z","iopub.execute_input":"2025-09-30T21:43:49.120747Z","iopub.status.idle":"2025-09-30T21:43:49.137603Z","shell.execute_reply.started":"2025-09-30T21:43:49.120726Z","shell.execute_reply":"2025-09-30T21:43:49.137019Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport ast\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\n\ndata['input_text'] = data['input_text'].astype(str).str.strip().str.replace('\\xa0', ' ')\ndata['input_text'] = data['input_text'].str.replace(r'\\s+', '', regex=True)\n\nchar2idx = {\"<PAD>\": 0, \"<UNK>\": 1}\nall_chars = sorted(set(\"\".join(data['input_text'].tolist())))\nfor i, c in enumerate(all_chars, start=2):\n    char2idx[c] = i\nvocab_size = max(char2idx.values()) + 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T21:44:00.867179Z","iopub.execute_input":"2025-09-30T21:44:00.867407Z","iopub.status.idle":"2025-09-30T21:44:08.871467Z","shell.execute_reply.started":"2025-09-30T21:44:00.867392Z","shell.execute_reply":"2025-09-30T21:44:08.870899Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def parse_labels(x):\n    if isinstance(x, list):\n        return x\n    if pd.isna(x):\n        return None\n    if isinstance(x, (int, float)):\n        return [int(x)]\n    if isinstance(x, str):\n        s = x.strip()\n    \n        try:\n            parsed = ast.literal_eval(s)\n            return parsed\n        except Exception:\n            s2 = s.replace('\\n', '').replace('\\r', '').strip()\n            try:\n                parsed = ast.literal_eval(s2)\n                return parsed\n            except Exception:\n                parts = s2.replace(',', ' ').split()\n                if all(p in {'0','1'} for p in parts):\n                    return [int(p) for p in parts]\n                return None\n    return None\n\ndata['labels_parsed'] = data['labels'].apply(parse_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T21:44:32.158921Z","iopub.execute_input":"2025-09-30T21:44:32.159634Z","iopub.status.idle":"2025-09-30T21:44:40.528376Z","shell.execute_reply.started":"2025-09-30T21:44:32.159607Z","shell.execute_reply":"2025-09-30T21:44:40.527802Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TextDataset(Dataset):\n    def __init__(self, df, char2idx):\n        self.rows = list(zip(df['input_text'].tolist(), df['labels_parsed'].tolist()))\n        self.char2idx = char2idx\n\n    def __len__(self):\n        return len(self.rows)\n\n    def __getitem__(self, idx):\n        text, labels = self.rows[idx]\n        x = torch.tensor([self.char2idx.get(c, self.char2idx['<UNK>']) for c in text], dtype=torch.long)\n        y = torch.tensor(labels, dtype=torch.long)\n        return x, y\n\ndef collate_fn(batch):\n    xs, ys = zip(*batch)\n    max_len = max(len(x) for x in xs)\n    xs_pad, ys_pad = [], []\n    for x, y in zip(xs, ys):\n        pad_x = torch.cat([x, torch.full((max_len - len(x),), char2idx[\"<PAD>\"], dtype=torch.long)])\n        pad_y = torch.cat([y, torch.full((max_len - len(y),), -100, dtype=torch.long)])\n        xs_pad.append(pad_x)\n        ys_pad.append(pad_y)\n    return torch.stack(xs_pad), torch.stack(ys_pad)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T21:44:45.959416Z","iopub.execute_input":"2025-09-30T21:44:45.959668Z","iopub.status.idle":"2025-09-30T21:44:45.966200Z","shell.execute_reply.started":"2025-09-30T21:44:45.959650Z","shell.execute_reply":"2025-09-30T21:44:45.965547Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_size = int(0.9 * len(data))\nval_size = len(data) - train_size\ntrain_df, val_df = random_split(data, [train_size, val_size])\n\ntrain_dataset = TextDataset(pd.DataFrame(train_df.dataset.iloc[train_df.indices]), char2idx)\nval_dataset = TextDataset(pd.DataFrame(val_df.dataset.iloc[val_df.indices]), char2idx)\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T21:44:49.363323Z","iopub.execute_input":"2025-09-30T21:44:49.363579Z","iopub.status.idle":"2025-09-30T21:44:49.611189Z","shell.execute_reply.started":"2025-09-30T21:44:49.363552Z","shell.execute_reply":"2025-09-30T21:44:49.610635Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class BiLSTM(nn.Module):\n    def __init__(self, vocab_size, embed_dim=128, hidden_dim=256, num_classes=2, pad_idx=0):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n        self.fc = nn.Linear(hidden_dim*2, num_classes)\n\n    def forward(self, x):\n        emb = self.embedding(x)\n        out, _ = self.lstm(emb)\n        logits = self.fc(out)\n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T21:45:01.222057Z","iopub.execute_input":"2025-09-30T21:45:01.222364Z","iopub.status.idle":"2025-09-30T21:45:01.227524Z","shell.execute_reply.started":"2025-09-30T21:45:01.222344Z","shell.execute_reply":"2025-09-30T21:45:01.226873Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = BiLSTM(vocab_size=vocab_size, embed_dim=128, hidden_dim=256, num_classes=2, pad_idx=char2idx[\"<PAD>\"]).to(device)\ncriterion = nn.CrossEntropyLoss(ignore_index=-100)\noptimizer = torch.optim.Adam(model.parameters(), lr=5e-4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T21:45:05.962134Z","iopub.execute_input":"2025-09-30T21:45:05.962653Z","iopub.status.idle":"2025-09-30T21:45:09.711795Z","shell.execute_reply.started":"2025-09-30T21:45:05.962630Z","shell.execute_reply":"2025-09-30T21:45:09.710972Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_accuracy(preds, labels):\n    mask = labels != -100\n    correct = (preds.argmax(-1) == labels) & mask\n    return correct.sum().item() / mask.sum().item()\n\nfor epoch in range(10):\n    model.train()\n    total_loss, total_acc, total_cnt = 0, 0, 0\n    for x_batch, y_batch in train_loader:\n        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n        optimizer.zero_grad()\n        logits = model(x_batch)\n        loss = criterion(logits.view(-1, 2), y_batch.view(-1))\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item() * x_batch.size(0)\n        total_acc += compute_accuracy(logits, y_batch) * x_batch.size(0)\n        total_cnt += x_batch.size(0)\n    print(f\"Epoch {epoch+1} | Train loss: {total_loss/total_cnt:.4f}, acc: {total_acc/total_cnt:.4f}\")\n\n    model.eval()\n    val_loss, val_acc, val_cnt = 0, 0, 0\n    with torch.no_grad():\n        for x_batch, y_batch in val_loader:\n            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n            logits = model(x_batch)\n            loss = criterion(logits.view(-1,2), y_batch.view(-1))\n            val_loss += loss.item() * x_batch.size(0)\n            val_acc += compute_accuracy(logits, y_batch) * x_batch.size(0)\n            val_cnt += x_batch.size(0)\n    print(f\"Val loss: {val_loss/val_cnt:.4f}, acc: {val_acc/val_cnt:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T21:45:15.266466Z","iopub.execute_input":"2025-09-30T21:45:15.267200Z","iopub.status.idle":"2025-09-30T21:54:41.573025Z","shell.execute_reply.started":"2025-09-30T21:45:15.267175Z","shell.execute_reply":"2025-09-30T21:54:41.572258Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_spaces(model, text, char2idx):\n    model.eval()\n    with torch.no_grad():\n        x = torch.tensor([char2idx.get(c, char2idx['<UNK>']) for c in text], dtype=torch.long).unsqueeze(0).to(device)\n        logits = model(x)\n        preds = logits.argmax(-1).squeeze(0).cpu().tolist()\n        positions = [i for i, v in enumerate(preds) if v==1]\n        return positions\n\nlines = []\nwith open('/kaggle/input/avito-ds-internship-2025/dataset_1937770_3.txt', 'r', encoding='utf-8') as f:\n    next(f) \n    for line in f:\n        line = line.strip()\n        if not line:\n            continue\n        parts = line.split(',', 1)\n        if len(parts) == 2:\n            id_, text_no_spaces = parts\n            lines.append((int(id_), text_no_spaces))\n\ntest = pd.DataFrame(lines, columns=['id', 'text_no_spaces'])\n\nall_positions = []\nfor sentence in test['text_no_spaces']:\n    all_positions.append(predict_spaces(model, sentence, char2idx))\n    \ntest['predicted_positions'] = all_positions\ntest.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T21:56:08.299961Z","iopub.execute_input":"2025-09-30T21:56:08.300252Z","iopub.status.idle":"2025-09-30T21:56:09.323994Z","shell.execute_reply.started":"2025-09-30T21:56:08.300231Z","shell.execute_reply":"2025-09-30T21:56:09.323263Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test.tail(15)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T21:56:15.193799Z","iopub.execute_input":"2025-09-30T21:56:15.194303Z","iopub.status.idle":"2025-09-30T21:56:15.205814Z","shell.execute_reply.started":"2025-09-30T21:56:15.194277Z","shell.execute_reply":"2025-09-30T21:56:15.205110Z"}},"outputs":[],"execution_count":null}]}